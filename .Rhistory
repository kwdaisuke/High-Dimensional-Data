<<<<<<< HEAD
b**2222222222222222222
ls()
murders
ls murders
ls
plot(a)
plot(murders)
new <- 1112
sentence <- "This is the new assignment of the sentences"
print(sentence)
plot(sentence)
a <- [1,2,4,5,6,]
a
plot(a, b)
ls
ls
ls
ls()
log(0)
log)100
log(19)
exp(10)
exponential()
exp()
exp(1)
log(a)
ln(1)
exp(1)
plot(exp(1))
log(exp(1))
log(exp(1))
help
help)()
help(log)
?log
?exp
?help
args(log)
log(8, base2)
log(10, base=3)
log(x=8, exp=2)
log(8, 2)
2^3^2^2^2^2^
2^
3
3^2
2^^
2*3
2**3
+
?+
?"+"
help
+
a
Co2
a
pi
inf
Inf
exp
ln
exp
pie
pi
This is the new script
class(ks)
clasS(ls)
library(dslabs)
data(murders)
murders
class(murders)
str
str(murders)
head(murders)
plot(murders)
murders$population
pop <- murders$population
length(pop)
0000000000000000000000000000000000000000000000000
codes <-c(111,111,122)
codes
country <-c("Japan", "Italy", "Spain")
country
codes <-(Japan=22, France=35, Canada=53,)
codes <-c(Japan=22, France=35, Canada=53,)
codes <-c(Japan=22, France=35, Canada=53)
codes
seq(1, 19)
plot(seq)
scatter(seq)
plot.scatter(seq)
plot(seq**2)
plot(seq)
seq(1, 100, 2)
plot(seq)
1:100
codes[2]
codes
codes[1]
codes[0]
codes[1]
codes[1:]
codes[1:2]
codes["Canada"]
plot(codes)
codes
as.character(code)
as.character(codes)
x <- c("1", "2", )
a+b+c
height <-c(1,,222,2,2)
height <-c(19, 20, 21, 22)
height
plot(height*4)
murders$state
plot(murders$state)
murders$state
m.
0
set.seed(42)
N <-10000
N
X <-sample.int(N, size=6, prob = 1/6)
sample.int(n = 6, size = N, prob = rep(1/6, 6), replace=True)
sample.int(n = 6, size = N, prob = rep(1/6, 6), replace=TRUE)
X<-sample.int(n = 6, size = N, prob = rep(1/6, 6), replace=TRUE)
x
X
Y <-sample.int(n = 6, size = N, prob = rep(1/6, 6), replace=TRUE)
Z <-pmax(X, Y)
Z
Z
X
z <- 1:6
z
px_theory <- (2 * z -1)/36
pz_emp <- prob.table(tba)
pz_emp <- prob.table(table(z))
pz_emp <- prob.table(table(Z))
pz_emp <- prop.table(table(Z))
pz_emp
round(100* cbind(pz_theory, pz_emp), 1)
pz_theory <- (2 * z -1)/36
pz_yhrotu
pz_theory
round(100* cbind(pz_theory, pz_emp), 1)
a = matrix(c(3,2,-1.-1))
a
a <-matrix(c(3,2,-1.-1),nrows=2)
a <-matrix(c(3,2,-1.-1),nrow=2)
a <-matrix(c(3,2,-1,-1),nrow=2)
a
a <-matrix(c(3,-1,2.-1),nrow=2)
a <-matrix(c(3,-1,2,-1),nrow=2)
a
B <- matrix(c(0,-1,5,3,3,2), nrow=3)
B
B <- matrix(c(0,-1,5,3,3,2), nrow=2)
B
A*B
a%*%B
A = c(2.5, 7.4, 8.0, 4.5, 7.4, 9.2)
A
mean(A)
std(A)
sd(A)
var(A)
sqrt(6)
(6.5+1.96)*(2.2/sqrt(6))
(6.5-1.96)*(2.2/sqrt(6))
(6.5+(1.96)*(2.2/sqrt(6))
s
(6.5+(1.96)*(2.2/sqrt(6))
a
6.5+(1.96)*(2.2/sqrt(6))
6.5-(1.96)*(2.2/sqrt(6))
A <- c(15.6,16.2, 22.5, 20.5, 16.4, 19.4, 16.6, 17.9, 12.7, 13.9)
A
mean(A)
sd(A)
-2.262*2.98
(-2.262*2.98)/sqrt(10)
(2.262*2.98)/sqrt(10)
17.17-2.1316
17.17+2.1316
62-1.96*(20/sqrt(80))
62+1.96*(20/sqrt(80))
90/17
runif(500, -10. 10)
set.seed(7)
set.seed(17)
runif(500, -10, 10)
X < -runif(500, -10, 10)
X
plot(X)
plot(1:500, X)
plot(1:501, X)
plot(0:500, X)
X
plot(-10:10, X)
plot(0:10000, X)
y = -2+3*X+rnorm(500, 0, 1)
y
L = lm(X, y)
L = lm(X~y)
L
summary(L)
A <-matrix(c(1,0,0,0,1,0,0,0,1), nrow=3)
A
solve(A)
x <- matrix(c(1,7,2))
y <- matrix(c(3,5,2))
cov(x, y)
A <- matrix(c(2,5,1,7,4,3), nrow=3)
A
A%*%t(A)
AT <- A%*%t(A)
AT
solve(AT)
A
det(A)
eigen(A)
library(Matrix)
eigen(A)
library(matliib)
library(matlib)
eigen(A)
A
eigen(AT)
AT
eigen(AT)
A]
A
solve(AT)
A <- matrix(c(2,5,1,7,4,3,4,5,2), nrow=3)
A
AT <- t(A)
AT
A%*%AT
solve(AT)
A%*%AT
AAT <-A%*%AT
solve(AAT)
AAT_inv <- solve(AAT)
AAT_inv
AAT%*%AAT_inv
## ECDF:
x <- rnorm(20)
#x <- rnorm(10000)
#x<- as.vector(AirPassengers)
#x<-c(92.00,76.00,100.00,92.00,100.00,64.00,56.00,80.00,48.00,96.00,56.00,96.00,40.00,72.00,100.00,80.00,92.00,96.00,96.00,56.00,96.00,28.00,64.00,80.00,88.00,48.00,92.00,96.00,60.00,84.00,88.00,64.00,88.00,56.00,60.00,84.00,88.00,80.00,64.00,80.00,20.00,76.00,24.00,92.00,40.00,64.00,56.00,8.00,76.00,84.00,72.00,88.00,60.00,92.00,84.00,76.00,100.00,92.00,100.00)
plot(x)
mean(x)
summary(x)
Fn <- ecdf(x)
print(Fn)
print(Fn(x))
print(summary(Fn))
plot(Fn)
print(quantile(x))
abline(v=quantile(x))
print(quantile(x,probs=seq(0,1,0.1)))
plot(Fn)
abline(v=quantile(x,probs=seq(0,1,0.1)))
hist(x,breaks=50)
## LLN:
n <- 100000
x <- rnorm(n,m=2)
print(sum(x)/n)
## independence:
x <- rnorm(100000)
y <- x^2
print(cov(x,y))
print(cov(cbind(x,y)))
z <- x^3
print(mean(z))
## pingpong/tennis deuce:
p <- seq(0,1,0.01)
win <- p^2/(1-2*p*(1-p))
plot(p,win)
abline(a=0,b=1
## ECDF:
x <- rnorm(20)
#x <- rnorm(10000)
#x<- as.vector(AirPassengers)
#x<-c(92.00,76.00,100.00,92.00,100.00,64.00,56.00,80.00,48.00,96.00,56.00,96.00,40.00,72.00,100.00,80.00,92.00,96.00,96.00,56.00,96.00,28.00,64.00,80.00,88.00,48.00,92.00,96.00,60.00,84.00,88.00,64.00,88.00,56.00,60.00,84.00,88.00,80.00,64.00,80.00,20.00,76.00,24.00,92.00,40.00,64.00,56.00,8.00,76.00,84.00,72.00,88.00,60.00,92.00,84.00,76.00,100.00,92.00,100.00)
plot(x)
mean(x)
summary(x)
Fn <- ecdf(x)
print(Fn)
print(Fn(x))
print(summary(Fn))
plot(Fn)
print(quantile(x))
abline(v=quantile(x))
print(quantile(x,probs=seq(0,1,0.1)))
plot(Fn)
abline(v=quantile(x,probs=seq(0,1,0.1)))
hist(x,breaks=50)
## LLN:
n <- 100000
x <- rnorm(n,m=2)
print(sum(x)/n)
## LLN:
n <- 100000
x <- rnorm(n,m=2)
print(sum(x)/n)
## independence:
x <- rnorm(100000)
y <- x^2
print(cov(x,y))
print(cov(cbind(x,y)))
z <- x^3
print(mean(z))
X1 = rexp(50, 0.2)
X1
A <- matrix(c(12,4,7,7,5,8,3,6,9), nrow=3)
A
B <- matrix(c(5,6,-22,8,7,5,1,3,9,2,0,1), nrow=3)
B
A%*%B
m=floor(2*n/3)
n=nrows(Pb)
u=1:n
W = matrix(norm(10*4))
W = matrix(norm(10*4), ncol=4)
W = matrix(rnorm(10*4), ncol=4)
W
Wb =w[c)2,5,6]
Wb =w[c(2,5,6), (1,4)]
wb
Wb =W[c(2,5,6), (1,4)]
Wb =W[c(2,5,6), c(1,4)]
wb
Wb
package.install("glmnet")
install.packages("glmnet")
fit1cv = cv.glmnet
setwd("C:/Users/daisu/OneDrive/Desktop/DSTI")
setwd("C:/Users/daisu/OneDrive/Desktop/DSTI/High Dimensional Data")
data(iris)
X = iris$Sepal.Length
hist(X)
hist(X,breaks = 100)
hist(X,freq = FALSE)
lines(density(X),col=2,lwd=2)
X = read.table("http://math.agrocampus-ouest.fr/infoglueDeliverLive/digitalAssets/108286_decatholon.csv", header=TRUE, sep=";")
X = read.table("http://math.agrocampus-ouest.fr/infoglueDeliverLive/digitalAssets/108286_decathlon.csv",header=TRUE,sep=';')
X
X
X = read.table("http://math.agrocampus-ouest.fr/infoglueDeliverLive/digitalAssets/108286_decathlon.csv",header=TRUE,sep=';')
dim(X)
decathlon = read.table("http://math.agrocampus-ouest.fr/infoglueDeliverLive/digitalAssets/108286_decathlon.csv",header=TRUE,sep=';')
dim(X)
X =  decathlon[,2:11]
X
X =  decathlon[,2:11]
rownames(X) = decathlon$X
X =  decathlon[,2:11]
rownames(X) = decathlon$X
X =  decathlon[,2:11]
rownames(X) = decathlon$X
X
pca = princomp(X)
biplot(pca)
pca
X[1,]
Y = predict(pca)[,1:2]
# coordinates of the 1st individual in the original space (X)
X[1,]
# coordinates of the 1st individual in the projection space (Y = X * U)
Y[1,]
plot(Y,col=cls)
X
decathlon
Y = predict(pca)[,'Classement']
Y = predict(pca)[,1:2]
# coordinates of the 1st individual in the original space (X)
X[1,]
# coordinates of the 1st individual in the projection space (Y = X * U)
Y[1,]
plot(Y)
decathlon
X[,1]
Y[1,]
decathlon
hist(X,breaks = 100)
text(X)
text(pca)
Y = predict(pca)[,1:2]
# coordinates of the 1st individual in the original space (X)
X[1,]
# coordinates of the 1st individual in the projection space (Y = X * U)
Y[1,]
plot(Y)
text(Y, labels=rownames(X))
Y = predict(pca)[,1:2]
# coordinates of the 1st individual in the original space (X)
X[1,]
# coordinates of the 1st individual in the projection space (Y = X * U)
Y[1,]
plot(Y)
text(Y, labels=rownames(X))
Y = predict(pca)[,1:2]
# coordinates of the 1st individual in the original space (X)
X[1,]
# coordinates of the 1st individual in the projection space (Y = X * U)
Y[1,]
plot(Y, type="n")
text(Y, labels=rownames(X))
Y = predict(pca)[,1:2]
# coordinates of the 1st individual in the original space (X)
X[1,]
# coordinates of the 1st individual in the projection space (Y = X * U)
Y[1,]
plot(Y, type='n')
text(Y, labels=rownames(X))
Y = predict(pca)[,1:2]
# coordinates of the 1st individual in the original space (X)
X[1,]
# coordinates of the 1st individual in the projection space (Y = X * U)
Y[1,]
plot(Y, type='n')
text(Y, labels=rownames(X))
pca = princomp(X)
biplot(pca, col=c(0,2))
pca = princomp(X)
par(mfrow=c(0,2))
pca = princomp(X)
par(mfrow=c(0,2))
pca = princomp(X)
par(mfrow=c(1,2))
biplot(pca, col=c(0,2))
pca = princomp(X)
par(mfrow=c(1,2))
biplot(pca, col=c(0,2))
pca = princomp(X)
par(mfrow=c(1,2))
biplot(pca, col=c(0,2))
pca = princomp(X)
par(mfrow=c(1,2))
biplot(pca, col=c(0,2))
pca = princomp(X)
par(mfrow=c(1,2))
biplot(pca, col=c(0,2))
pca = princomp(X)
par(mfrow=c(1,2))
biplot(pca, col=c(0,2))
pca = princomp(X)
par(mfrow=c(1,2))
biplot(pca, col=c(0,2))
pca = princomp(X)
par(mfrow=c(1,2))
biplot(pca, col=c(0,2))
Y = predict(pca)[,1:2]
# coordinates of the 1st individual in the original space (X)
X[1,]
# coordinates of the 1st individual in the projection space (Y = X * U)
Y[1,]
plot(Y, type='n')
text(Y, labels=rownames(X))
pca = princomp(X)
par(mfrow=c(1,2))
biplot(pca, col=c(0,2))
Y = predict(pca)[,1:2]
plot(Y, type='n')
text(Y, labels=rownames(X))
hist(X,breaks = 100)
data(iris)
X = iris$Sepal.Length
hist(X)
hist(X,breaks = 100)
boxplot(X)
par(mfrow=c(2,1))
hist(X,freq = FALSE)
lines(density(X),col=2,lwd=2)
boxplot(X,horizontal = TRUE)
boxplot(iris[,-5])
par(mfrow=c(2,2))
for (j in 1:4) boxplot(iris[,j],main=paste('variable',j))
pca = princomp(X)
par(mfrow=c(1,2))
biplot(pca, col=c(0,2))
pca = princomp(X)
par(mfrow=c(1,2))
biplot(pca, col=c(0,2))
X =  decathlon[,2:11]
rownames(X) = decathlon$X
pca = princomp(X)
par(mfrow=c(1,2))
biplot(pca, col=c(0,2))
Y = predict(pca)[,1:2]
plot(Y, type='n')
text(Y, labels=rownames(X))
summary(pca)
screeplot(pca)
# 500m has a strong correlation ← means very important
pca = princomp(X, cor = TRUE)
par(mfrow=c(1,2))
biplot(pca, col=c(0,2))
Y = predict(pca)[,1:2]
plot(Y, type='n')
text(Y, labels=rownames(X))
# 500m has a strong correlation ← means very important
pca = princomp(X)
par(mfrow=c(1,2))
biplot(pca, col=c(0,2))
Y = predict(pca)[,1:2]
plot(Y, type='n')
text(Y, labels=rownames(X))
=======
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
n = nrow(X)
err = c()
for (i in 1:10){
learn = sample(1:n, 2/3*n)
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[-learn,])
# Compute the classification error
err[i] = sum(Y[-learn] != ystar$class) / length(ystar$class)
}
boxplot(err)
library(MASS)
V = 25
n = nrow(X)
fold = rep(1:V, n/V)
err.knn = err.lda = rep(NA, V)
for (v in 1:V){
learn = which(fold != v)
test = which(fold == v)
# KNN (with an internal CV for picking K)
X2 = X[learn,]; Y2 = Y[learn]
K = 30; n2 = nrow(X2)
fold2 = rep(1:V, n2/V)
err.knn2 = matrix(NA, K, V)
for (v2 in 1:v){ # Start of the internal CV
learn2 = which(fold2 != v2)
test2 = which(fold2 == v2)
for (k in 1:K){
ystar = knn(X2[learn2,], X2[test2,], Y2[learn2], k)
err.knn2[k, v2] = sum(ystar != Y2[test2]) / length(ystar)
}
}
Kstar = which.min(rowMeans(err.knn2)) 3 Choice of K* for this fold
library(MASS)
V = 25
n = nrow(X)
fold = rep(1:V, n/V)
err.knn = err.lda = rep(NA, V)
for (v in 1:V){
learn = which(fold != v)
test = which(fold == v)
# KNN (with an internal CV for picking K)
X2 = X[learn,]; Y2 = Y[learn]
K = 30; n2 = nrow(X2)
fold2 = rep(1:V, n2/V)
err.knn2 = matrix(NA, K, V)
for (v2 in 1:v){ # Start of the internal CV
learn2 = which(fold2 != v2)
test2 = which(fold2 == v2)
for (k in 1:K){
ystar = knn(X2[learn2,], X2[test2,], Y2[learn2], k)
err.knn2[k, v2] = sum(ystar != Y2[test2]) / length(ystar)
}
}
Kstar = which.min(rowMeans(err.knn2)) # Choice of K* for this fold
# Evaluation of the error for this fold
ystar = knn(X[learn,], X[test, ], y[learn], k=Kstar)
err.knn[v] = sum(ystar != Y[test]) / length(ystar)
# LDA
f <- lda(X[learn,], Y[learn])
ystar = predict(f, X[test,])$class
err.lda[v] = sum(ystar != Y[test]) /length(ystar)
}
data(iris)
X = iris[,-5]
Y = as.numeric(iris$Species)
xstar = c(6, 2.9, 5, 3)
f, svm = svm(X, Y, kernel = 'radial', gamma = 1, type = 'C-classification')
data(iris)
X = iris[,-5]
Y = as.numeric(iris$Species)
xstar = c(6, 2.9, 5, 3)
f.svm = svm(X, Y, kernel = 'radial', gamma = 1, type = 'C-classification')
install.package('e1071')
install.packages('e1071')
library(e1071)
data(iris)
X = iris[,-5]
Y = as.numeric(iris$Species)
xstar = c(6, 2.9, 5, 3)
f.svm = svm(X, Y, kernel = 'radial', gamma = 1, type = 'C-classification')
ystar = predict(f.svm, matrix(xstar, nrow=1))
ystar
rep(10, 10)
rep(10, 2)
V = 25 ; GAMMA = seq(0.01, 1, by=0.01) # GAMMA is always smaller than 1
n = nrow(X)
fold = rep(1:V, n/V)
err.svm = matrix(NA, K, V)
for (v in 1:V){
learn = which(fold !=v)
test = which(fold == v)
for (j in 1:length(GAMMA)){
gamma = GAMMA[j]
f.svm = svm(X[learn,], Y[learn], kernel = 'radial', gamma-gamma,
type = "C-classification")
ystar = predict(f.svm, X[test,])
err.svm[j,v] = sum(ystar != Y[test]) / length(ystar)  }
}
V = 25 ; GAMMA = seq(0.01, 1, by=0.01) # GAMMA is always smaller than 1
n = nrow(X)
fold = rep(1:V, n/V)
err.svm = matrix(NA, K, V)
for (v in 1:V){
learn = which(fold !=v)
test = which(fold == v)
for (j in 1:length(GAMMA)){
gamma = GAMMA[j]
f.svm = svm(X[learn,], Y[learn], kernel = 'radial', gamma-gamma,
type = "C-classification")
ystar = predict(f.svm, X[test,])
err.svm[j,v] = sum(ystar != Y[test]) / length(ystar)  }
}
V = 25 ; GAMMA = seq(0.01, 1, by=0.01) # GAMMA is always smaller than 1
n = nrow(X)
fold = rep(1:V, n/V)
err.svm = matrix(NA, length(GAMMA), V)
for (v in 1:V){
learn = which(fold !=v)
test = which(fold == v)
for (j in 1:length(GAMMA)){
gamma = GAMMA[j]
f.svm = svm(X[learn,], Y[learn], kernel = 'radial', gamma-gamma,
type = "C-classification")
ystar = predict(f.svm, X[test,])
err.svm[j,v] = sum(ystar != Y[test]) / length(ystar)
}
}
plot(GAMMA, rowMeans(err.svm), type='b')
V = 25 ; GAMMA = seq(0.01, 1, by=0.01) # GAMMA is always smaller than 1
n = nrow(X)
fold = rep(1:V, n/V)
err.svm = matrix(NA, length(GAMMA), V)
for (v in 1:V){
learn = which(fold != v)
test = which(fold == v)
for (j in 1:length(GAMMA)){
gamma = GAMMA[j]
f.svm = svm(X[learn,], Y[learn], kernel = 'radial', gamma-gamma,
type = "C-classification")
ystar = predict(f.svm, X[test,])
err.svm[j,v] = sum(ystar != Y[test]) / length(ystar)
}
}
plot(GAMMA, rowMeans(err.svm), type='b')
V = 25 ; GAMMA = seq(0.01, 1, by=0.01) # GAMMA is always smaller than 1
n = nrow(X)
fold = rep(1:V, n/V)
err.svm = matrix(NA, length(GAMMA), V)
for (v in 1:V){
learn = which(fold != v)
test = which(fold == v)
for (j in 1:length(GAMMA)){
gamma = GAMMA[j]
f.svm = svm(X[learn,], Y[learn], kernel = 'radial', gamma-gamma,
type = "C-classification")
ystar = predict(f.svm, X[test,])
err.svm[j,v] = sum(ystar != Y[test]) / length(ystar)
}
}
plot(GAMMA, rowMeans(err.svm), type='b')
which(c(1,2,3,4,5,6,7,8,9,10))
data(iris)
X = iris[,-5]
Y = as.numeric(iris$Species)
pca = princomp(X)
bplot(pca)
data(iris)
X = iris[,-5]
Y = as.numeric(iris$Species)
pca = princomp(X)
biplot(pca)
data("AirPassengers")
str(AirPassengers)
varicelle<-ts(data$x, start=c(1931, 1), end=c(1972, 6), freq=12)
plot(varicelle)
data = read.csv()
#install.packages("depmixS4")
library("depmixS4")
#install.packages("quantmod")
library("quantmod")
setwd("/Users/emisohpi/Desktop/DataFluct/アズビル")
df <- read.csv("cleaned.csv")
date <- as.character(df[,1])
date_TS<- as.POSIXlt(date) # Create date and time objects
TSData <- data.frame(df[,2], row.names=date_TS)
TSData <- as.xts(TSData) # Build our time series dataset
colnames(TSData) <- "pulse"
HMM <- depmix(list(pulse~1), data=TSData, nstates=20, family=list(poisson()))
data(swiss)
?swiss
library(class)
?hclust
library(class)
?hclust
D = dist(swiss)
hc = hclust(D, method="complete")
plot(hc)
library(class)
?hclust
D = dist(swiss)
hc = hclust(D, method="complete")
plot(hc)
82)
library(class)
?hclust
D = dist(swiss)
hc = hclust(D, method="complete")
plot(hc)
library(tidyverse)
library(cluter)
install.packages("cluter")
install.packages("factoextra")
install.packages("gridExtra")
install.packages("factoextra")
swiss
kmeans2 <- kmeans(swiss)
kmeans2 <- kmeans(as.matrix(swiss))
as.matrix(swiss)
kmeans2 <- kmeans(as.matrix(swiss), centers=2)
kmeans
str(kmeans2)
fviz_cluster(kmeans2, data=swiss)
library(gridExtra)
kmeans2 <- kmeans(as.matrix(swiss), centers=2)
fviz_cluster(kmeans2, data=swiss)
library(gridExtra)
fviz_cluster(kmeans2, data=swiss)
library(class)
?hclust
D = dist(swiss)
par(mfrow=c(2,2))
hc1 = hclust(D, method="complete"); plot(hc1)
hc2 = hclust(D, method="single"); plot(hc2)
hc3 = hclust(D, method="centroid"); plot(hc3)
hc4 = hclust(D, method="word.D2");plot(hc4)
library(class)
?hclust
D = dist(swiss)
par(mfrow=c(2,2))
hc1 = hclust(D, method="complete"); plot(hc1)
hc2 = hclust(D, method="single"); plot(hc2)
hc3 = hclust(D, method="centroid"); plot(hc3)
hc4 = hclust(D, method="ward.D2");plot(hc4)
hc4=hclust(D,method="ward.D2")
cl4=cutree(hc4, k=2)
cl4
plot(cl4)
hc4=hclust(D,method="ward.D2")
cl4=cutree(hc4, k=2)
plot(cl4, colnames(hc4))
help(cl4)
??cl4
?cl4
??cutree
hc4=hclust(D,method="ward.D2")
cl4=cutree(hc4, k=2)
cutree_1h.dendrogram(hc4, h=50)
hc4=hclust(D,method="ward.D2")
cl4=cutree(hc4, k=2)
cl4
hc4=hclust(D,method="ward.D2")
cl4=cutree(hc4, k=2)
dennd=as.dendrogram(hc4)
hc4=hclust(D,method="ward.D2")
cl4=cutree(hc4, k=2)
dend=as.dendrogram(hc4)
cutree_1h.dendrogram(dend, h=50)
hc4=hclust(D,method="ward.D2")
cl4=cutree(hc4, k=2)
cl4
plot(swiss, col=cl4, pch=19)
library(class)
?hclust
D = dist(swiss)
par(mfrow=c(2,2))
hc1 = hclust(D, method="complete"); plot(hc1)
hc2 = hclust(D, method="single"); plot(hc2)
hc3 = hclust(D, method="centroid"); plot(hc3)
hc4 = hclust(D, method="ward.D2");plot(hc4)
hc4=hclust(D,method="ward.D2")
cl4=cutree(hc4, k=2)
cl4
install.packages("cluter")
install.packages("factoextra")
install.packages("gridExtra")
library(tidyverse)
library(cluter)
install.packages("gridExtra")
#install.packages("cluter")
#install.packages("factoextra")
#install.packages("gridExtra")
library(tidyverse)
library(cluter)
install.packages("cluter")
install.packages("factoextra")
install.packages("gridExtra")
library(tidyverse)
library(cluter)
install.packages("gridExtra")
#install.packages("cluter")
#install.packages("factoextra")
#install.packages("gridExtra")
library(tidyverse)
library(cluter)
install.packages("cluter")
#install.packages("factoextra")
#install.packages("gridExtra")
library(tidyverse)
library(cluter)
>>>>>>> a2a45e0460d8215c73d8f1c79ab932a289c710a4
